{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-13T10:39:42.826704Z",
     "start_time": "2025-10-13T10:39:33.752735Z"
    }
   },
   "source": [
    "# Plotting suite update: ALWAYS highlight 0s for any TARGET variable\n",
    "# Saves EVERY figure as a PDF in the current working directory.\n",
    "# Targets' time series: red markers at zeros\n",
    "# Targets' histograms: overlay a red \"zero bar\" showing count of zeros\n",
    "# Targets' scatters (vs ENV features): red points where target==0\n",
    "# Supports ENV_VARS stored as single columns of 24-hour FLOAT vectors (00..23)\n",
    "# Computes FULL-day and OVERNIGHT (prev 18:00–23:59 + curr 00:00–05:59) stats\n",
    "\n",
    "import ast\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# config\n",
    "CSV_PATH     = \"Final_2015_Data_Site8.csv\"  # <-- set this\n",
    "DATE_COL     = \"Date\"\n",
    "WINDOW_START = \"2015-07-01\"\n",
    "WINDOW_END   = \"2015-10-31\"\n",
    "\n",
    "PRECIP_COL   = \"Precipitation\"   # daily scalar\n",
    "ENV_VARS     = [\"Temperature\", \"Humidity\", \"Dew_Point\", \"Water_Temperature\"]  # each row holds a 24h FLOAT vector (00..23) in ONE column\n",
    "TARGETS      = [\"Adults_8_Col\", \"Adults_8_Gam0\"]  # zeros treated as missing (highlighted)\n",
    "\n",
    "SAVE_AGGREGATED_CSV = False\n",
    "AGG_OUT_PATH = \"aggregated_env_features.csv\"\n",
    "\n",
    "# saving controls (all PDFs saved here; default is current dir)\n",
    "SAVE_PDFS = True\n",
    "SAVE_DIR = Path(\".\")  # current working directory\n",
    "_SAVE_COUNT = {}\n",
    "\n",
    "def _slug(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", str(s)).strip(\"_\")\n",
    "\n",
    "def _savefig_pdf(name: str):\n",
    "    \"\"\"Save current matplotlib figure as a PDF with a clean, collision-safe filename.\"\"\"\n",
    "    if not SAVE_PDFS:\n",
    "        return None\n",
    "    SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    name = _slug(name)\n",
    "    n = _SAVE_COUNT.get(name, 0)\n",
    "    _SAVE_COUNT[name] = n + 1\n",
    "    fname = f\"{name}.pdf\" if n == 0 else f\"{name}__{n+1}.pdf\"\n",
    "    path = SAVE_DIR / fname\n",
    "    plt.savefig(path, bbox_inches=\"tight\")\n",
    "    plt.close()  # free memory for large batches\n",
    "    print(f\"[saved] {path}\")\n",
    "    return str(path)\n",
    "\n",
    "# HELPERS\n",
    "def _standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def _parse_and_sort_dates(df: pd.DataFrame, date_col: str) -> pd.DataFrame:\n",
    "    if date_col not in df.columns:\n",
    "        raise ValueError(f\"DATE_COL '{date_col}' not found in CSV.\")\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values(date_col).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def _filter_window(df: pd.DataFrame, date_col: str, start: str, end: str) -> pd.DataFrame:\n",
    "    mask = (df[date_col] >= pd.to_datetime(start)) & (df[date_col] <= pd.to_datetime(end))\n",
    "    return df.loc[mask].reset_index(drop=True)\n",
    "\n",
    "def _parse_vec24_cell(cell) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parse a 24-length vector cell robustly into float array of length 24.\n",
    "    Accepts:\n",
    "      - Python/JSON-like list strings: \"[1, 2, 3, ...]\"\n",
    "      - Comma-separated string: \"1,2,3,...\"\n",
    "      - Whitespace-separated: \"1 2 3 ...\"\n",
    "      - Already list/tuple/array\n",
    "    Returns np.array of float(24), or np.full(24, np.nan) if parsing fails/length != 24.\n",
    "    \"\"\"\n",
    "    if isinstance(cell, (list, tuple, np.ndarray)):\n",
    "        arr = np.array(cell, dtype=float)\n",
    "    else:\n",
    "        s = str(cell).strip()\n",
    "        arr = None\n",
    "        try:\n",
    "            parsed = ast.literal_eval(s)\n",
    "            if isinstance(parsed, (list, tuple, np.ndarray)):\n",
    "                arr = np.array(parsed, dtype=float)\n",
    "        except Exception:\n",
    "            arr = None\n",
    "        if arr is None:\n",
    "            s2 = s.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            parts = [p.strip() for p in (s2.split(\",\") if \",\" in s2 else s2.split())]\n",
    "            try:\n",
    "                arr = np.array([float(x) if x != \"\" else np.nan for x in parts], dtype=float)\n",
    "            except Exception:\n",
    "                return np.full(24, np.nan, dtype=float)\n",
    "    if arr.size != 24:\n",
    "        return np.full(24, np.nan, dtype=float)\n",
    "    return arr.astype(float)\n",
    "\n",
    "def _env_matrix_from_vector_column(df: pd.DataFrame, base: str) -> np.ndarray:\n",
    "    if base not in df.columns:\n",
    "        raise ValueError(f\"ENV column '{base}' not found in CSV.\")\n",
    "    vecs = df[base].apply(_parse_vec24_cell).to_numpy()\n",
    "    mat = np.vstack(vecs)  # (n, 24)\n",
    "    if mat.shape[1] != 24:\n",
    "        raise ValueError(f\"ENV '{base}' did not parse to 24 values per row.\")\n",
    "    return mat\n",
    "\n",
    "def _full_day_stats(mat24: np.ndarray) -> dict[str, np.ndarray]:\n",
    "    return {\n",
    "        \"FULL_min\":    np.nanmin(mat24, axis=1),\n",
    "        \"FULL_max\":    np.nanmax(mat24, axis=1),\n",
    "        \"FULL_median\": np.nanmedian(mat24, axis=1),\n",
    "        \"FULL_sd\":     np.nanstd(mat24, axis=1, ddof=0),\n",
    "    }\n",
    "\n",
    "def _overnight_stats(mat24: np.ndarray) -> dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    For date i: prev day hours 18..23 + current day 0..5  -> align to current date (i).\n",
    "    First row has no previous day -> NaNs.\n",
    "    \"\"\"\n",
    "    n = mat24.shape[0]\n",
    "    ov = np.full((n, 12), np.nan, dtype=float)\n",
    "    if n >= 2:\n",
    "        prev_18_23 = mat24[:-1, 18:24]\n",
    "        curr_00_05 = mat24[1:,  0:6]\n",
    "        ov[1:, :] = np.concatenate([prev_18_23, curr_00_05], axis=1)\n",
    "    return {\n",
    "        \"OV_min\":    np.nanmin(ov, axis=1),\n",
    "        \"OV_max\":    np.nanmax(ov, axis=1),\n",
    "        \"OV_median\": np.nanmedian(ov, axis=1),\n",
    "        \"OV_sd\":     np.nanstd(ov, axis=1, ddof=0),\n",
    "    }\n",
    "\n",
    "# Plot helpers (each saves a PDF)\n",
    "def _time_series_generic(date, y, title, ylabel, save_name=None):\n",
    "    fig, ax = plt.subplots(figsize=(11, 5))\n",
    "    ax.plot(date, y, marker=\"o\", linewidth=1.5, label=ylabel)\n",
    "    ax.set_xlim(date.min() - pd.Timedelta(days=2), date.max() + pd.Timedelta(days=2))\n",
    "    ax.margins(x=0.0, y=0.08)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b\"))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    _savefig_pdf(save_name or f\"{ylabel}__time_series\")\n",
    "\n",
    "def _time_series_target(date, y, title, ylabel, save_name=None):\n",
    "    \"\"\"Time series for TARGET: ALWAYS highlight 0s in red.\"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    zero_mask = (y == 0)\n",
    "    fig, ax = plt.subplots(figsize=(11, 5))\n",
    "    ax.plot(date, y, marker=\"o\", linewidth=1.5, label=ylabel)\n",
    "    if np.any(zero_mask):\n",
    "        ax.scatter(date[zero_mask], y[zero_mask], s=90, color=\"red\", zorder=5, label=\"Zero (treated as missing)\")\n",
    "    ax.set_xlim(date.min() - pd.Timedelta(days=2), date.max() + pd.Timedelta(days=2))\n",
    "    ax.margins(x=0.0, y=0.08)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b\"))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    _savefig_pdf(save_name or f\"{ylabel}__time_series_target\")\n",
    "\n",
    "def _ribbon(date, y_min, y_max, y_med, title, ylabel, range_label=\"Range (min–max)\", med_label=\"Median\", save_name=None):\n",
    "    fig, ax = plt.subplots(figsize=(11, 5))\n",
    "    ax.fill_between(date, y_min, y_max, alpha=0.2, label=range_label)\n",
    "    ax.plot(date, y_med, marker=\"o\", linewidth=1.5, label=med_label)\n",
    "    ax.set_xlim(date.min() - pd.Timedelta(days=2), date.max() + pd.Timedelta(days=2))\n",
    "    ax.margins(x=0.0, y=0.08)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b\"))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    _savefig_pdf(save_name or f\"{ylabel}__ribbon\")\n",
    "\n",
    "def _hist_generic(y, title, xlabel, save_name=None):\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.hist(pd.Series(y).dropna(), bins=\"auto\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    _savefig_pdf(save_name or f\"{xlabel}__hist\")\n",
    "\n",
    "def _hist_target(y_all, title, xlabel, save_name=None):\n",
    "    y_all = pd.Series(y_all, dtype=float)\n",
    "    total_count   = int(y_all.notna().sum())\n",
    "    zero_count    = int((y_all == 0).sum())\n",
    "    nonzero_vals  = y_all[(y_all != 0) & y_all.notna()]\n",
    "    nonzero_count = int(nonzero_vals.shape[0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    counts, bins, _ = ax.hist(nonzero_vals.to_numpy(), bins=\"auto\", label=f\"Non-zero: {nonzero_count}\")\n",
    "\n",
    "    if zero_count > 0:\n",
    "        width = (bins[1] - bins[0]) * 0.9 if len(bins) >= 2 else 1.0\n",
    "        ax.bar(0, zero_count, width=width, color=\"red\", alpha=0.6,\n",
    "               label=f\"Zeros: {zero_count} | Total: {total_count}\", zorder=5)\n",
    "    else:\n",
    "        ax.bar(0, 0, width=1.0, alpha=0.0, label=f\"Zeros: 0 | Total: {total_count}\")\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    _savefig_pdf(save_name or f\"{xlabel}__hist_target\")\n",
    "\n",
    "def _scatter_env_vs_target(x, y_target, title, xlabel, ylabel, save_name=None):\n",
    "    \"\"\"\n",
    "    Scatter of ENV feature vs TARGET with 0s highlighted in red.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y_target, dtype=float)\n",
    "    zero_mask = (y == 0)\n",
    "    ok = ~np.isnan(x) & ~np.isnan(y)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.8, 6.8))\n",
    "    ax.scatter(x[ok & ~zero_mask], y[ok & ~zero_mask], marker=\"o\", alpha=0.9, label=\"Observed\")\n",
    "    if np.any(ok & zero_mask):\n",
    "        ax.scatter(x[ok & zero_mask], y[ok & zero_mask], s=90, color=\"red\", zorder=5, label=\"Target == 0 (missing)\")\n",
    "\n",
    "    if np.any(ok):\n",
    "        x_min, x_max = np.nanmin(x[ok]), np.nanmax(x[ok])\n",
    "        y_min, y_max = np.nanmin(y[ok]), np.nanmax(y[ok])\n",
    "        span_x = x_max - x_min if np.isfinite(x_max - x_min) else 1.0\n",
    "        span_y = y_max - y_min if np.isfinite(y_max - y_min) else 1.0\n",
    "        pad_x = max(0.5, 0.06 * span_x)\n",
    "        pad_y = max(0.5, 0.06 * span_y)\n",
    "        ax.set_xlim(x_min - pad_x, x_max + pad_x)\n",
    "        ax.set_ylim(y_min - pad_y, y_max + pad_y)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    _savefig_pdf(save_name or f\"scatter__{_slug(ylabel)}__vs__{_slug(xlabel)}\")\n",
    "\n",
    "def _corr_heatmap(df_num: pd.DataFrame, title: str, save_name=None):\n",
    "    corr = df_num.corr(method=\"pearson\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    im = ax.imshow(corr, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(corr.shape[1]))\n",
    "    ax.set_yticks(range(corr.shape[0]))\n",
    "    ax.set_xticklabels(corr.columns, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(corr.index)\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\"Pearson r\")\n",
    "    plt.tight_layout()\n",
    "    _savefig_pdf(save_name or \"correlation_heatmap\")\n",
    "\n",
    "# PIPELINE\n",
    "# Load, tidy, window\n",
    "df0 = pd.read_csv(CSV_PATH, sep=None, engine=\"python\")\n",
    "df0 = _standardize_columns(df0)\n",
    "df0 = _parse_and_sort_dates(df0, DATE_COL)\n",
    "\n",
    "# ENV features (FULL day + OVERNIGHT), computed BEFORE windowing (to keep prev-day context)\n",
    "agg_cols = []\n",
    "for base in ENV_VARS:\n",
    "    mat24 = _env_matrix_from_vector_column(df0, base)  # (n,24), floats\n",
    "    # full-day\n",
    "    full_stats = _full_day_stats(mat24)\n",
    "    for k, v in full_stats.items():\n",
    "        col = f\"{base}_{k}\"\n",
    "        df0[col] = v\n",
    "        agg_cols.append(col)\n",
    "    # overnight\n",
    "    ov_stats = _overnight_stats(mat24)\n",
    "    for k, v in ov_stats.items():\n",
    "        col = f\"{base}_{k}\"\n",
    "        df0[col] = v\n",
    "        agg_cols.append(col)\n",
    "\n",
    "# Targets (mark zeros and non-zero convenience)\n",
    "for tgt in TARGETS:\n",
    "    if tgt not in df0.columns:\n",
    "        raise ValueError(f\"TARGET '{tgt}' not found in CSV.\")\n",
    "    df0[f\"{tgt}_is_zero\"] = (df0[tgt] == 0)\n",
    "\n",
    "# Filter window for plotting\n",
    "df = _filter_window(df0, DATE_COL, WINDOW_START, WINDOW_END)\n",
    "date = df[DATE_COL].to_numpy()\n",
    "\n",
    "# PLOTS\n",
    "# Precipitation (generic time series + hist)\n",
    "if PRECIP_COL in df.columns:\n",
    "    _time_series_generic(date, df[PRECIP_COL].to_numpy(), f\"{PRECIP_COL} - Daily\", PRECIP_COL,\n",
    "                         save_name=\"precipitation__time_series\")\n",
    "    _hist_generic(df[PRECIP_COL], f\"{PRECIP_COL} - Distribution\", PRECIP_COL,\n",
    "                  save_name=\"precipitation__hist\")\n",
    "else:\n",
    "    print(f\"[WARN] '{PRECIP_COL}' not found; skipping precip plots.\")\n",
    "\n",
    "# ENV ribbons & hist - FULL day\n",
    "for base in ENV_VARS:\n",
    "    _ribbon(date,\n",
    "            df[f\"{base}_FULL_min\"].to_numpy(),\n",
    "            df[f\"{base}_FULL_max\"].to_numpy(),\n",
    "            df[f\"{base}_FULL_median\"].to_numpy(),\n",
    "            title=f\"{base} - FULL DAY Range (min–max) with Median\",\n",
    "            ylabel=f\"{base} (full day)\",\n",
    "            range_label=\"Full-day range (min–max)\",\n",
    "            med_label=\"Full-day median\",\n",
    "            save_name=f\"{base}__FULL__ribbon\")\n",
    "    _hist_generic(df[f\"{base}_FULL_median\"], f\"{base} - FULL Median Distribution\",\n",
    "                  f\"{base} (FULL median)\", save_name=f\"{base}__FULL__median_hist\")\n",
    "    _hist_generic(df[f\"{base}_FULL_sd\"],     f\"{base} - FULL SD Distribution\",\n",
    "                  f\"{base} (FULL sd)\", save_name=f\"{base}__FULL__sd_hist\")\n",
    "\n",
    "# ENV ribbons & hist - OVERNIGHT\n",
    "for base in ENV_VARS:\n",
    "    _ribbon(date,\n",
    "            df[f\"{base}_OV_min\"].to_numpy(),\n",
    "            df[f\"{base}_OV_max\"].to_numpy(),\n",
    "            df[f\"{base}_OV_median\"].to_numpy(),\n",
    "            title=f\"{base} - OVERNIGHT Range (min–max) with Median\",\n",
    "            ylabel=f\"{base} (overnight)\",\n",
    "            range_label=\"Overnight range (min–max)\",\n",
    "            med_label=\"Overnight median\",\n",
    "            save_name=f\"{base}__OVERNIGHT__ribbon\")\n",
    "    _hist_generic(df[f\"{base}_OV_median\"], f\"{base} - OVERNIGHT Median Distribution\",\n",
    "                  f\"{base} (OV median)\", save_name=f\"{base}__OVERNIGHT__median_hist\")\n",
    "    _hist_generic(df[f\"{base}_OV_sd\"],     f\"{base} - OVERNIGHT SD Distribution\",\n",
    "                  f\"{base} (OV sd)\", save_name=f\"{base}__OVERNIGHT__sd_hist\")\n",
    "\n",
    "# Targets: ALWAYS highlight zeros\n",
    "for tgt in TARGETS:\n",
    "    y_all = df[tgt].to_numpy(dtype=float)\n",
    "    _time_series_target(date, y_all, f\"{tgt} - Daily Counts (Zeros highlighted)\", tgt,\n",
    "                        save_name=f\"{tgt}__time_series\")\n",
    "    _hist_target(y_all, f\"{tgt} - Distribution (Non-zero + Zero bar)\", tgt,\n",
    "                 save_name=f\"{tgt}__hist\")\n",
    "\n",
    "# Scatter: target vs ENV medians (FULL and OVERNIGHT), with zeros highlighted\n",
    "for tgt in TARGETS:\n",
    "    y_all = df[tgt].to_numpy(dtype=float)\n",
    "    for base in ENV_VARS:\n",
    "        x_full = df[f\"{base}_FULL_median\"].to_numpy()\n",
    "        _scatter_env_vs_target(x_full, y_all,\n",
    "                               f\"{tgt} vs {base} (FULL median) - Daily\",\n",
    "                               f\"{base} (FULL median)\", tgt,\n",
    "                               save_name=f\"scatter__{tgt}__{base}__FULL_median\")\n",
    "        x_ov = df[f\"{base}_OV_median\"].to_numpy()\n",
    "        _scatter_env_vs_target(x_ov, y_all,\n",
    "                               f\"{tgt} vs {base} (OVERNIGHT median) - Daily\",\n",
    "                               f\"{base} (OV median)\", tgt,\n",
    "                               save_name=f\"scatter__{tgt}__{base}__OV_median\")\n",
    "\n",
    "# Correlation heatmap (using targets as values but treating zeros as NaN)\n",
    "corr_df = pd.DataFrame(index=df.index)\n",
    "for base in ENV_VARS:\n",
    "    for stat in [\"FULL_min\", \"FULL_max\", \"FULL_median\", \"FULL_sd\", \"OV_min\", \"OV_max\", \"OV_median\", \"OV_sd\"]:\n",
    "        corr_df[f\"{base}_{stat}\"] = df[f\"{base}_{stat}\"]\n",
    "if PRECIP_COL in df.columns:\n",
    "    corr_df[PRECIP_COL] = df[PRECIP_COL]\n",
    "for tgt in TARGETS:\n",
    "    corr_df[tgt] = df[tgt].where(df[tgt] != 0, np.nan)  # zeros -> NaN for correlation\n",
    "corr_df = corr_df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "_corr_heatmap_name = \"correlation__FULL_OV_env_precip_targets\"\n",
    "_corr_heatmap(corr_df, \"Correlation - FULL & OVERNIGHT ENV features, Precipitation, Targets (zeros→NaN)\",\n",
    "              save_name=_corr_heatmap_name)\n",
    "\n",
    "# Save aggregated (optional)\n",
    "if SAVE_AGGREGATED_CSV:\n",
    "    keep = [DATE_COL] + ([PRECIP_COL] if PRECIP_COL in df0.columns else []) + agg_cols + TARGETS\n",
    "    df0[keep].to_csv(AGG_OUT_PATH, index=False)\n",
    "    print(f\"[saved] {AGG_OUT_PATH}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:115: RuntimeWarning: All-NaN slice encountered\n",
      "  \"FULL_min\":    np.nanmin(mat24, axis=1),\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:116: RuntimeWarning: All-NaN slice encountered\n",
      "  \"FULL_max\":    np.nanmax(mat24, axis=1),\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:133: RuntimeWarning: All-NaN slice encountered\n",
      "  \"OV_min\":    np.nanmin(ov, axis=1),\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:134: RuntimeWarning: All-NaN slice encountered\n",
      "  \"OV_max\":    np.nanmax(ov, axis=1),\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:115: RuntimeWarning: All-NaN slice encountered\n",
      "  \"FULL_min\":    np.nanmin(mat24, axis=1),\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:116: RuntimeWarning: All-NaN slice encountered\n",
      "  \"FULL_max\":    np.nanmax(mat24, axis=1),\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:133: RuntimeWarning: All-NaN slice encountered\n",
      "  \"OV_min\":    np.nanmin(ov, axis=1),\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:134: RuntimeWarning: All-NaN slice encountered\n",
      "  \"OV_max\":    np.nanmax(ov, axis=1),\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:115: RuntimeWarning: All-NaN slice encountered\n",
      "  \"FULL_min\":    np.nanmin(mat24, axis=1),\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:116: RuntimeWarning: All-NaN slice encountered\n",
      "  \"FULL_max\":    np.nanmax(mat24, axis=1),\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:133: RuntimeWarning: All-NaN slice encountered\n",
      "  \"OV_min\":    np.nanmin(ov, axis=1),\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:134: RuntimeWarning: All-NaN slice encountered\n",
      "  \"OV_max\":    np.nanmax(ov, axis=1),\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:115: RuntimeWarning: All-NaN slice encountered\n",
      "  \"FULL_min\":    np.nanmin(mat24, axis=1),\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:116: RuntimeWarning: All-NaN slice encountered\n",
      "  \"FULL_max\":    np.nanmax(mat24, axis=1),\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:133: RuntimeWarning: All-NaN slice encountered\n",
      "  \"OV_min\":    np.nanmin(ov, axis=1),\n",
      "/var/folders/ck/yp00zrfx3pz5x6_mjzfr6hy00000gn/T/ipykernel_71199/539248373.py:134: RuntimeWarning: All-NaN slice encountered\n",
      "  \"OV_max\":    np.nanmax(ov, axis=1),\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/Users/pradumchauhan/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] precipitation__time_series.pdf\n",
      "[saved] precipitation__hist.pdf\n",
      "[saved] Temperature__FULL__ribbon.pdf\n",
      "[saved] Temperature__FULL__median_hist.pdf\n",
      "[saved] Temperature__FULL__sd_hist.pdf\n",
      "[saved] Humidity__FULL__ribbon.pdf\n",
      "[saved] Humidity__FULL__median_hist.pdf\n",
      "[saved] Humidity__FULL__sd_hist.pdf\n",
      "[saved] Dew_Point__FULL__ribbon.pdf\n",
      "[saved] Dew_Point__FULL__median_hist.pdf\n",
      "[saved] Dew_Point__FULL__sd_hist.pdf\n",
      "[saved] Water_Temperature__FULL__ribbon.pdf\n",
      "[saved] Water_Temperature__FULL__median_hist.pdf\n",
      "[saved] Water_Temperature__FULL__sd_hist.pdf\n",
      "[saved] Temperature__OVERNIGHT__ribbon.pdf\n",
      "[saved] Temperature__OVERNIGHT__median_hist.pdf\n",
      "[saved] Temperature__OVERNIGHT__sd_hist.pdf\n",
      "[saved] Humidity__OVERNIGHT__ribbon.pdf\n",
      "[saved] Humidity__OVERNIGHT__median_hist.pdf\n",
      "[saved] Humidity__OVERNIGHT__sd_hist.pdf\n",
      "[saved] Dew_Point__OVERNIGHT__ribbon.pdf\n",
      "[saved] Dew_Point__OVERNIGHT__median_hist.pdf\n",
      "[saved] Dew_Point__OVERNIGHT__sd_hist.pdf\n",
      "[saved] Water_Temperature__OVERNIGHT__ribbon.pdf\n",
      "[saved] Water_Temperature__OVERNIGHT__median_hist.pdf\n",
      "[saved] Water_Temperature__OVERNIGHT__sd_hist.pdf\n",
      "[saved] Adults_8_Col__time_series.pdf\n",
      "[saved] Adults_8_Col__hist.pdf\n",
      "[saved] Adults_8_Gam0__time_series.pdf\n",
      "[saved] Adults_8_Gam0__hist.pdf\n",
      "[saved] scatter__Adults_8_Col__Temperature__FULL_median.pdf\n",
      "[saved] scatter__Adults_8_Col__Temperature__OV_median.pdf\n",
      "[saved] scatter__Adults_8_Col__Humidity__FULL_median.pdf\n",
      "[saved] scatter__Adults_8_Col__Humidity__OV_median.pdf\n",
      "[saved] scatter__Adults_8_Col__Dew_Point__FULL_median.pdf\n",
      "[saved] scatter__Adults_8_Col__Dew_Point__OV_median.pdf\n",
      "[saved] scatter__Adults_8_Col__Water_Temperature__FULL_median.pdf\n",
      "[saved] scatter__Adults_8_Col__Water_Temperature__OV_median.pdf\n",
      "[saved] scatter__Adults_8_Gam0__Temperature__FULL_median.pdf\n",
      "[saved] scatter__Adults_8_Gam0__Temperature__OV_median.pdf\n",
      "[saved] scatter__Adults_8_Gam0__Humidity__FULL_median.pdf\n",
      "[saved] scatter__Adults_8_Gam0__Humidity__OV_median.pdf\n",
      "[saved] scatter__Adults_8_Gam0__Dew_Point__FULL_median.pdf\n",
      "[saved] scatter__Adults_8_Gam0__Dew_Point__OV_median.pdf\n",
      "[saved] scatter__Adults_8_Gam0__Water_Temperature__FULL_median.pdf\n",
      "[saved] scatter__Adults_8_Gam0__Water_Temperature__OV_median.pdf\n",
      "[saved] correlation__FULL_OV_env_precip_targets.pdf\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "670bfdf6b04e796a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
